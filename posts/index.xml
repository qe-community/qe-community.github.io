<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Quality &amp; Efficiency</title><link>https://qe-community.github.io/posts/</link><description>Recent content in Posts on Quality &amp; Efficiency</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright><lastBuildDate>Wed, 11 Aug 2021 10:02:59 +0800</lastBuildDate><atom:link href="https://qe-community.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>寻找软件研发效能的合适指标-下篇</title><link>https://qe-community.github.io/posts/findefficiencyindicatorsthree/</link><pubDate>Wed, 11 Aug 2021 10:02:59 +0800</pubDate><guid>https://qe-community.github.io/posts/findefficiencyindicatorsthree/</guid><description>本文由张思楚发表 本系列的 上篇 咱们尝试回答了最近几年 “软件研发效能” 为什么会成为业界的热词 “Buzzword” ，有哪些合适的软件研发效能度量指标这两个问题。中篇 分析了软件研发效能度量过程中的三个观点和观察，&amp;ldquo;本篇&amp;rdquo; 希望能找到一个快速选择合适度量指标的方案，并聊聊在度量上下文中的 fuzzy front end.
软件研发效能的度量指标和工具链越来越丰富，主打数字化转型的企业在内部也开始建设自己的效能中台了，作为一线研发人员，面对这些眼花缭乱的指标、工具和平台，不经要问：我需要把这些东西都实践了吗？什么是我最需要做的，什么是我现阶段的优先级? 在 &amp;ldquo;上篇&amp;rdquo; 中咱们提到，研发效能的度量很大程度上取决于公司的类型，规模，文化，与之合作的项目类型等因素。 一个团队的度量指标很可能与其他公司或团队的完全不同，这是完全正常的事情。那么有没有一个稍微简单的方式能帮我们快速识别一些更适合现阶段的度量指标呢?
###三种项目类型 在软件研发过程中，一般会经过三个阶段或者说接手三种类型的项目：绿地项目、棕地(黄地)项目、红地项目，（下文使用: 绿地、黄地、红地与之对应并简化代表），好像一个软件系统的生命周期。通过识别项目类型来找到此类型合适的度量指标，这可能是一个快速高效的方案。
绿地：
“In software development, a greenfield project could be one of developing a system for a totally new environment, without concern for integrating with other systems, especially not legacy systems. Such projects are deemed higher risk, as they are often for new infrastructure, new customers, and even new owners.</description></item><item><title>改进故事卡返工率</title><link>https://qe-community.github.io/posts/reducestoryrework/</link><pubDate>Mon, 12 Jul 2021 10:31:00 +0800</pubDate><guid>https://qe-community.github.io/posts/reducestoryrework/</guid><description>名词解释： AC：全称为Acceptance Criteria，即验收标准，写在每张故事卡上，代表每张卡需要进行验证的具体测试场景和测试点。
Kick off：Dev在进行开发之前，和QA、BA、UX同事进行需求确认，确保大家对需求的理解一致，并且讨论出更完善的场景。
Desk Check：Dev在开发完故事卡后，按照验收标准给QA、BA、UX同事进行演示，确保功能的正确性。
故事卡返工：在 Desk Check 或者 In QA 阶段，发现故事卡中的一些重大问题，Dev重新拿回这张卡继续工作。
Showcase：产品或功能演示，向团队成员演示已完成的功能。
项目背景： 这是一个稳定运行2年多的前端项目，BA和QA人员基本变动很小，Dev经历了一些变化，目前有三位前端Dev + 一位后端Dev。团队氛围比较好，大家都比较包容，相处十分融洽，可能正是因为这样好的氛围和合作让我们大家都有所松懈，才会产生一些影响交付质量和交付效率的问题。
下面我们使用黄金圈法则来介绍整个改进过程的来龙去脉，先简单介绍一下黄金圈法则： 它是一种以目标为中心的思维方式，强调要按照目标—方法—行动（Why-How-What）的顺序思考问题。
Why：为什么做一件事，目标和信念
How：怎么做，是实现目标的途径
What：事情的表象，具体实施的动作与达到的结果
那么我们就来看下整个改进过程是如何发生的，以及结果是怎么样的。
Why? 为什么要做这个改进工作？主要是来自QA童鞋的困扰，比较频繁的发现团队在Desk Check以及In QA阶段发现问题，总结为以下三点：
Desk Check有时发现部分AC没有满足 Desk Check时一些在AC之外的基本功能没有满足 In QA发现一些UI或者功能问题，导致开发返工 这些在Desk Check或者In QA发现的问题，都会导致故事卡的返工，大家重复的开发和测试，以及多次的Desk Check也会占有大家更多的时间，给大家造成很大的困扰。
所以我们的目标就是降低故事卡返工率，让开发过程更顺利，大家有更好的工作体验，也可以有更多的时间去做更有价值的事情。
How? 针对我们之前提到的问题，我们进行逐一分析，寻找解决方案：
Desk Check有时发现部分AC没有满足 首先这次Desk Check可以算是失败的，需要Dev进行相关工作后进行多一次Desk Check，对于引入的BA、QA人员造成额外时间的消耗 对于Dev本身需要重新熟悉代码逻辑，花费更多的时间，同时也会对Desk Check的失败会感到尴尬，影响到大家对他专业度的评价
Desk Check时一些在AC之外的基本功能没有满足 原始AC由BA进行编写，QA和Dev在做卡之前进行相应的补充和调整，很显然，Dev和QA的补充工作做的并不是很好，这里我们需要一些改进
In QA发现一些UI或者功能问题，导致开发返工 对于Dev，顺利Desk Check之后，会接收新的卡，对于需要返工的卡，需要进行优先级对比，如果需要修复的话，则会打断当前开发思路 对于QA，将问题反馈给Dev，测试工作也会被打断，Dev修复后，QA需要进行反复的测试工作，耗费更多的时间 从上面这些问题可以看到我们在Kick off 以及 Desk check这些实践上做的不够好，我们可以从改进这两个敏捷实践入手，通过一些小的活动保证我们项目高质量高效率的交付，我们需要更加正视每个敏捷实践，让其发挥最大价值。</description></item><item><title>寻找软件研发效能的合适指标-中篇</title><link>https://qe-community.github.io/posts/findefficiencyindicatorstwo/</link><pubDate>Tue, 22 Jun 2021 11:02:59 +0800</pubDate><guid>https://qe-community.github.io/posts/findefficiencyindicatorstwo/</guid><description>本文由张思楚发表 上篇中，咱们尝试回答了最近几年 “软件研发效能” 为什么会成为业界的热词 “Buzzword” ，有哪些合适的软件研发效能指标这两个问题。接下来希望根据团队的情况，界定的团队上下文，给出一些推荐的度量指标。为了让这些内容更加有上下文和代入感，这里加入本文作为中篇，在本篇里说说下面三个观察和观点。
###观察和观点一：莫让度量变目标。
经济学家 查尔斯·古德哈特 在1975提出了古德哈特定律: When a measure becomes a target, it ceases to be a good measure. “当一个度量本身成为目标时，它就不再是一个好的度量”。根据我们在项目中的观察和经验，古德哈特定律不光适用于经济学领域，一样适用于软件研发领域。此定律在现实中的故事: 在法国殖民时期的越南，那里鼠患成灾，所以当地政府想出办法：为每只死去的老鼠提供奖励，民众只需要上交死老鼠的尾巴。不久之后，越南的街头就出现了没有尾巴的老鼠，人们为了持续盈利，并没有杀死老鼠，而只是切下它的尾巴，等待它去生新老鼠给自己赚钱。在正常情况下，「被切下的老鼠尾巴的数量」与「死去老鼠的数量」正相关，是一个好的指标。可是，一旦政府把「被切下的老鼠尾巴的数量」变成大家的优化目标，就会产生未曾预料到的结果。简单来说，这种度量变成了目标，驱动并产生了“上有政策，下有对策。” 在软件研发领域里，当你度量团队产出的代码行数并设置目标时，比如: 800行/人天，聪明的程序员，就会被驱动去优化「代码行数」并让它达到目标。比如: 多加点中间变量，多加点注释，多抽点方法和测试，目标不就达成了吗? (曾见过方法实现只有两行代码，注释20多行，而且在工程里经常看到类似的注释和方法。) 这种目标度量会给业务带来价值吗? 再比如你度量并设置团队每个迭代需要完成Story的点数或者个数的时候，比如: 20点/迭代，团队就会被驱动优化「Story点数」并让它达到目标。比如: BA和Dev在开迭代计划会议的时候多估算一点，多拆一些卡，目标不就达成了吗？(曾听到有团队的卡墙上有一张三个点的Team Building卡。 Create DB这种操作原来估1个点，现在估3个点。为了不影Cycle time的统计, 由于第三方依赖阻塞的卡，阻塞不好推动，也不想持续识别并推动了，移回Backlog。) 这种目标度量会给业务带来价值吗？它是否可以落实到具体的管理或技术实践中？
让度量指标和数据收集尽量真实，需要关注的是趋势和阻塞。
在上面的案例里，统计每个迭代完成的卡，需要观察其趋势，一般情况下，每个迭代完成的卡，会在一个合理的区间内波动。(好比：用听诊器测量每分钟的心跳，非运动状态在 60~100bpm 次/分钟 都属于正常) 观察趋势并识别阻塞和阻塞的原因，加以针对性的治理，从而加速卡的流动，是度量的意义。而不是简单的和其他团队比较，粗狂的设定一个目标，驱使团队产生未曾预料的结果。
图表标识：某团队24个迭代所完成故事点统计图上图是一个项目24个迭代，每个迭代完成故事卡点数的统计图。由于团队所工作的业务领域没有变化，团队在此业务领域越来越熟练，所以总体交付趋势逐渐是上升的，交付速率逐步在一个合理区间内波动。观察并分析交付点数波动较大的迭代，分析并采取行动：
迭代7到迭代8，单个故事卡过大，拆卡质量不高，沟通复杂性增加，单卡开发时长增加，速率下降。行动：开发人员与业务分析师紧密沟通，在工作开始时将其拆解成更独立，更小的故事卡。
迭代14到迭代15，由于开发过程中所依赖的第三方API出现问题，无法按时对接，有累计超过10个点的卡延迟交付，不能贡献给本迭代，但会在下个迭代第三方API完工后完成，并体现在下个迭代。行动：及时的沟通和追踪依赖系统的情况并进行开发任务的调整，防止阻塞与等待的发生。
###观察和观点二：一个无法拆解的度量指标，可能不是一个好的度量指标。
可拆解的指标和结果才是一个好的指标。变更前置时长 (Lead time for change) 或者需求交付时长，是一个很好的结果性指标，能帮助并促进价值流的交付。但是你只是捕获需求提出的时间点和需求上线的时间点，并计算这两个点之间的耗时以此进行度量和阻塞识别，这是非常困难的。因为跨度太大，包括的因素太多，你很难看清楚到底发生了什么，到底在那个阶段什么因素导致了阻塞。
杜邦分析法 就是问题拆解的经典应用，拆解某个不容易看清楚的大问题到若干个子问题，通过分析若干子问题从而解决原来的大问题。比如分析并优化股本回报率这个一下看不清楚的大问题，拆解: 股本回报率（ROE）= 利润率 × 资产周转率 × 权益乘数 = (净收入 / 营业收入) × (营业收入 / 资产) × (资产/ 股东权益) 从而将无法直接分析和优化的股本回报率，变得更容易分析和优化，同时再次钻取这些子问题，直到找出一个个更加显而易见的指标。 图表标识：杜邦分析模型图表标识：杜邦分析图那么为什么可以借鉴杜邦分析法来拆解研发效能？因为研发效能也是一个不容易看清楚的大问题，需要拆解到若干个子问题，通过分析若干子问题从而解决原来的大问题，同时它是一个可分阶段度量拆解的指标，并且每阶段都可以再次细分、拆解。 图表标识：需求交付时长拆解图如上图，一个需求交付时长的拆解，通过不断的拆解找到更细化、具体的指标，找到优化点。 需求从提出到上线总花费时长为：21.</description></item><item><title>精益敏捷，禅茶一味</title><link>https://qe-community.github.io/posts/leanagile/</link><pubDate>Thu, 06 May 2021 10:16:00 +0800</pubDate><guid>https://qe-community.github.io/posts/leanagile/</guid><description>提起精益，是否有这种感觉，虽然知晓它的丰田轶事也曾辗转于其中高深难懂的术语不能自拔，对于在软件项目如何使用这样的实践还是无所适从；说到敏捷，有没有觉察到，虽然市场上满是声称敏捷的项目但多数依旧李逵李鬼不辨，是是而非混杂。同作为一种流程，精益和敏捷本身也有一些或大或小的瑕疵或需要规避的缺点，这又从理论上增加了实践使用的难度。
在学习精益和敏捷的时候，我有了上面这些感慨却也不知如何解答。直到读了《金矿》这本书，深深折服于这样以小说的叙事来像讲故事一样把晦涩的专业术语娓娓道来，好个禅意自中悟；复杂的流程理论又在项目日常的推进中深入浅出，恰似好茶回味长。我不禁想自己也来煮一杯关于精益敏捷故事的茶，点起檀香闭目参禅。
故事开篇 话说有这样一个自动化测试项目，由于多种原因，到某年的8月，团队还有四个客户系统的自动化工作需要完成，此时距原计划的结项时间仅剩一月余，要达成合同约定的交付内容显然还有很长的路要走。在这样的背景下有一个叫李凯文的PM加入了这个项目，赶在当年年底以很好的客户满意度完结这个项目是他和团队成员的目标。这个的故事就从这里开始。
初进项目，包括内部合作和客户关系在内的很多事都要从零做起，面对这样紧迫的时间目标，如何才能带领团队圆满完成余下的工作呢？凯文不知道。他能想到并确信的是：团队需要改变之前的工作方式。
使用设计思维调整方向 从8月15到30号(饱含着对新开始的向往和美好寓意，后来这两周被命名为迭代一)，凯文首先约了客户最重要的干系人：琳达，来谈论项目范围和时间。那是一个非常诚恳和直率的谈话，或许是依赖于他们团队在前半段合作中与客户建立了密切的合作友谊，亦或是凯文这样爽快的态度打动了琳达，她同意将该项目自动化的目标从对每个客户系统开发尽可能多的自动化测试用例调整成一个更加实际且灵活的目标：为每个系统设计并创建适合的自动化测试框架作为MVP来指引客户团队后续的自动化案例编写。相应的凯文更新了项目计划，包括一份新的甘特图，自动化任务染色板和迭代燃起图。这样，团队有了新的方向，而整个后半段工作划分为九个迭代并用新的任务看板可视化跟踪。而这开局的第一个迭代，两位出色的团队成员分别搭建了客户系统System 2和System 3的自动化工程架构而且在System 2完成了一个功能模块的自动化脚本作为扩展示例。
完整的敏捷闭环 在迭代二，伴随着模块功能自动化脚本编码工作的推进，团队和琳达对于项目文档交付物的细节以及交接里程碑达成了约定，本着持续交付的宗旨，凯文也开始了对已完成自动化编码的系统System 1的文档编写工作。他们尝试使用一个可以匿名投票的看板做了年后第一次回顾会议，会议频率也被优化为两个迭代一次。时至今日凯文依然还记得匿名投票的方式是如何帮助团队在新员工加入之初就让大家能敞开心扉来讨论，那么飞快地在客户关系上打开局面。这次迭代会议，凯文的团队才真正走完了敏捷流程的一次闭环。但他们在这个过程中的优化绝不只是这里提到的这点，迭代会议上和客户人员一致投票产出的举措，给予团队大步向前的信心。
图例: 适应自动化测试交付项目的敏捷流程 引入持续改善 有什么地方我们还可以改善？从迭代三开始凯文就在团队中时不时问这个问题也经常扪心自问。
他们开始按周在团队成员中对敏捷会议的Host轮转；使用了新设计的PPT模板，这份更贴合客户品牌内涵的模板获得了多次手动点赞，而在某一次的Showcase上他们用PPT玩的彩蛋也带给了现场很多欢笑；大家开始对客户团队的三名成员进行自动化知识和技能培训，教授他们与团队一起建立起两方协同工作的大自动化团队，客户特别期待凯文的团队从敏捷实践和能力养成方面带动他们。这中间有一个特别值得说的插曲，当已经在offshore完成自动化的系统System 1在客户onshore环境调试的任务转回凯文团队手里的时候，团队成员普遍是不想接受的(基于和客户前期的约定onshore程序调试工作由客户内部团队承担)。当时客户的目标用户对这部分工作催得紧而恰巧客户从内部短时间又无法协调到合适人力，经过几次内部讨论，在了解更多外围信息后他们才慢慢认同了这部分调试工作是当前从客户需求上优先级最高的内容，并且有原则的接收了它。这件事使得团队更深刻理解了在敏捷实践中拥抱变化的含义，也将持续快速为客户带来最有价值的交付设定为他们团队的北极星指标。
引入现地现物 有一名新成员加入，这是迭代四第一天的好消息。作为庆祝，凯文预约了一个每日15分钟的Code review会议。为什么这样做呢？参考精益中的现地现物理念，他期望大家每天能亲临现场获取最直接的状态。而Code review就是这样一个身临其境的机会，让团队能重新思考，评价和讨论他们每天的代码产出。从这个环节，大家持续不断地把新提出的改善建议添加到看板，进行优先级排序后高优先级的会被优先处理予以解决，之后总会伴随着一个对效果的查看环节。你有没有觉得似曾相识？没错，就是PMP流程管理中的戴明PDCA环。而当团队将戴明环与精益结合使用，就生成了下图的模型。
图例: 加入PDCA的精益环路 加强团队合作 在项目的状态由橙色渐渐变回绿色的过程中，凯文的团队也越来越感到团队合作的重要性，这在迭代五的工作中尤为明显。这个项目有一个尚未提到的特殊点：项目的相关方来自五家不同的公司，这包括客户甲方公司，系统供应商公司和包括凯文所在公司的三家项目承接方。客户甲方负责制定项目里程碑，他们团队日常工作的具体需求来自一家上游项目承接方，同时团队工作的技术支持和环境可用性又依托系统供应商公司的配合。通过几次磨合，团队获得的经验是，三方合作首先要做的同时也是最难做到的是对某一在讨论的问题统一目标，理清各种制约条件，然后对每项生成的工作项指派确定的责任人以及进度检查点。最后再次使用戴明环对工作进行跟踪直到圆满完结。
图例: 项目相关方关系图 随着项目走上轨道，工作越来越像顺水行舟。这个项目逐渐很平稳得推进，最终做到清晰的计划，充分的准备，每天新的进展，优秀的演示和愉快的回顾。凯文成功的和团队一起在年底顺利完成项目结项，他们和客户也度过了繁忙难忘但愉快满意的合作。
写在最后 这个使用Lean-Agile融合实践优化项目进度的故事就讲完了，如果有人问：“带给这个团队走向成功最关键的因素是什么”？我会说：“是凯文这个团队内部以及与客户之间的信任”。这份信任稳固并加速了他们Lean-Agile流程的运用，而Lean-Agile的使用又反过来建立并加深了大家之间的信任。你觉得呢？
图例: Lean-Agile项目流程</description></item><item><title>Metrik - A Four Key Metrics Measurement Tool</title><link>https://qe-community.github.io/posts/4keymetrik/</link><pubDate>Fri, 23 Apr 2021 17:25:59 +0800</pubDate><guid>https://qe-community.github.io/posts/4keymetrik/</guid><description>本文由SEA 4 key metrics team发表 Hello everyone! We are delighted to announce the first release of Metrik - an automation tool that pulls data out of various types of CD pipelines and analysis the four key metrics trends for delivery teams who want to evaluate, improve their delivery performance.
With the first version rolled out, we have also open-sourced the project in GitHub: https://github.com/thoughtworks/metrik ###About four key metrics
Four key metrics was firstly introduced in State of DevOps report in 2014 and marked as ADOPT by ThoughtWorks Tech Radar in 2019.</description></item><item><title>敏捷质量成熟度模型</title><link>https://qe-community.github.io/posts/agilequalitymodel/</link><pubDate>Thu, 22 Apr 2021 10:16:59 +0800</pubDate><guid>https://qe-community.github.io/posts/agilequalitymodel/</guid><description>我们的世界，遍布着各种需求。 生活中，我们面临着生理需求，安全需求，尊严需求；工作中，我们处理着项目需求，社交需求，自我实现需求。
每个需求，都有解决的方法。下面这三个需求，也是这样：
评估需求：我项目的质量管理具体处于什么水平？
成长需求：我可以从哪些方面提升当前项目的质量管理？
指导需求：新开的项目如何准确选择测试实践来采用？
以上需求对应的三个问题都源于我们日常项目中的质量管理范畴。在寻求答案和解决方法之前，我们先仔细梳理一下这几个需求。
对于这个评估需求，要处理它我们主要考虑做到 - - 多维。
对于成长需求最关键的是 - - 参照。
而最后的指导需求，前两个需求都处理后，所生成的多维的评估和参照标准被众人接受，并归纳成某种理论，这个理论即可作为测试实践工具箱对项目选择进行指导。
而我们在这里所特指的这个理论，就是它。
它是一个分析模型，一个关于敏捷质量成熟度的分析模型。
该模型适用于敏捷流程的项目进行质量管理分析。使用者分别从六个维度(质量内建理念，测试左移，测试策略集，测试方法集，快速交付和测试右移)依据项目团队的现状，对四十一个不同的评估细则进行团队自我评价，填写一定的分值以采集量化分析所需的源数据。模型配套使用Excel文件工具通过内设的汇算逻辑自动绘制敏捷雷达和量表图以展示项目团队的质量管理成熟度。 该模型的展现效果包括两部分，即敏捷质量管理雷达和量表。
质量管理雷达 从六个不同维度对质量管理实践的采用(和使用程度)进行量化展示，并可视化在敏捷项目之间进行多维度横向对比或项目内部不同时间段的纵向对比。
质量管理量表 将雷达图中六个不同维度对质量管理实践的采用(和使用程度)进行降维展示，并提供在相似敏捷项目之间进行综合质量管理能力度量的对比支持。 模型的演进 构思和创建模型时，对质量管理维度的划分，我参照了SAFe以及精益敏捷思维中关于内建质量的观点及部分推荐实践，演绎出了质量内建理念和快速交付两个评估维度，从质量观念和服务交付方面进行对项目分析评价。另一方面，本着为敏捷团队质量管理提供实战性的质量实践工具箱的目标，我结合业界流行的测试实践和自己在质量分析领域的多年经验，归纳出了测试策略集，测试方法集，测试左移和测试右移四个评估维度，在质量把控的战略/战术和最佳实践层面进行考量。 综合来看，六个维度的覆盖面可以概括为，以质量内建理念为核心思想，测试策略集为战略指导，测试方法集为战术实施，结合测试左移和测试右移等优秀实践，从而完成快速交付以实现客户服务为中心的项目目标。
模型的解析 让我们来逐一认识六大维度的不同评估细则：
维度一：质量内建理念 评估细则 评价释义或示例 敏捷架构 系统各模块在架构中的耦合性和重用性是否适当？ 结对编程 开发过程中对于Pair Programming的使用 测试优先，全员参与 全体角色成员对于质量责任的共同承担，测试驱动开发和测试思维的渗透性 持续测试 增量测试的使用 团队质量准则 文档类标准和共识，如Story模板，Coding standard，Kick-off流程，卡的返工率等 资产集体所有权 成员对项目代码，系统环境等资产的权限共有和知识同步 维度二：测试左移 评估细则 评价释义或示例 Discovery 成员对质量的思维和思考是否体现在Discovery或类似需求调研阶段 Inception 成员对质量的思维和思考是否体现在Inception或类似Story拆解阶段 Card kick-off 开卡过程是否有对测试场景，解决方案影响范围等质量相关的讨论 Regular code diff 代码Diff活动的定期举行，在过程中讨论修改影响区域和回归范围等 Dev self-test 开发人员对新提交代码的自测活动 Desk-check Desk Check活动的举行，是代码移交测试阶段的评审仪式 维度三：测试策略集 评估细则 评价释义或示例 功能测试 对于系统在功能操作及其可用性的验证，包括黑盒/白盒测试 易用性测试 对于系统在便捷性，易用度，共识习惯等方面的验证 性能测试 对于系统在并发使用状态下响应速度，承压能力等方面的验证 安全测试 对于系统在敏感数据加密，安全攻击防御等方面的验证 无障碍测试 对于系统被有障碍人士（如视觉障碍）使用场景的验证 接口测试 对于系统后端提供的服务接口的直接性验证 合规性测试 对于在部分国家或地区合理遵守针对特定行业或产品类型的法律法规的验证 维度四：测试方法集 评估细则 评价释义或示例 自动化单元测试 开发人员对于代码逻辑的单元测试 静态代码分析工具 对代码静态扫描流行工具的使用，如Sonar 契约测试 依据预定的接口契约对服务接口和前端消费者的分离测试，通常涉及接口虚拟化 冒烟/回归测试 通过对测试用例的优先级划分和分类管理，实现对系统进行冒烟和回归性测试 自动化测试 使用代码或脚本对系统进行自动测试，并具有适当的覆盖率 探索性测试 使用基于时间盒和无测试用例的方式，基于经验，快速学习性的对系统进行测试 E2E测试 从业务流出发对系统进行关联的上下游子系统间联动性测试 混沌工程 在分布式系统进行的实验性测试，验证系统在部分服务或基础架构宕机的情况下的响应和恢复。示例工具如：Chaos Monkey 测试辅助工具 使用自有脚本或代码提高完成一些测试类任务的效率 Bug-Bash使用 召集不同角色和人员对系统实施有计划的团体测试活动 维度五：快速交付 评估细则 评价释义或示例 部署流水线 对持续集成和持续部署平台的使用(CI/CD, Pipeline) 基础设施/配置即代码 基础设施和配置信息代码化 分支管理准则 对master/branch代码分支在团队中使用的规则和实践 快速发布 实现较频繁的发布(如：频率在两周内)，增量发布 蓝绿部署/灰度发布 对产品线上功能可见度拥有针对代码版本的灵活控制 Rollout Plan上线计划 对发布过程的计划和对回滚的准备 维度六：测试右移 评估细则 评价释义或示例 产品上线验证 产品发布后在线上环境的验证确认，包括A/B测试 线上功能监控 产品环境对功能使用的自动监控和警报 线上负载监控 产品环境对性能和负载的自动监控和警报 PIR线上问题调查 对线上缺陷的根因分析，提升和规避对策讨论 产品线上缺陷汇总 对线上缺陷的整理和汇总报表，如个数月度比/严重级别月度比 用户反馈收集和迭代 将真实用户的建议反馈给项目团队的流程和需求转化 模型的外沿 在模型使用的过程中，我注意到访谈的参会者会对某些评估细则缺乏了解，比如E2E测试和探索性测试，从而造成评分困难。遇到这样的情况，会有两种可能的风险，第一是在简易模式的评分中把项目组在使用的测试实践误认为是E2E测试而给出1&amp;ndash;已采用的分值，第二是在复杂模式的评分中无法准确评价实践采用程度(2&amp;ndash;中等程度，3&amp;ndash;优良程度)。对于这两种情况，首先需要对该项评估细则相关的知识点和实施方式做详细的附加介绍，然后依据业界在该评估细则涉及的核心思想或推荐实践来对当前项目的采用程度进行评分。 当取得模型评估细则所需分值并生成质量管理雷达和量表后，我们从中获知了项目在质量管理方面多维量化的长板和短板，当前模型的使用即告一段落。对于质量管理短板的补齐顺序和提升实施，我们可以借助波士顿矩阵分析图(常说的四象限图)进行排序取舍，而后选定具体的发力点。具体问题具体分析，来制定适宜的可实施计划并进行推进和跟踪。 而对于质量管理量表最终分值的参照标准，鉴于项目类型，特点和所处阶段的千差万别，我并未给出一种普适的优劣评分办法。所谓“指法无优劣，功力有高下”，建议可以在具有相似性(比如同一个类型下)的项目之间做质量管理的横向比较，也可以将自己项目本身在不同时段的质量管理度量做纵向比较，以达到自省和自我促进。</description></item><item><title>寻找软件研发效能的合适指标</title><link>https://qe-community.github.io/posts/findefficiencyindicators/</link><pubDate>Tue, 20 Apr 2021 11:02:59 +0800</pubDate><guid>https://qe-community.github.io/posts/findefficiencyindicators/</guid><description>本文由张思楚发表 最近几年 “软件研发效能” 成了业界的热词 “Buzzword” ，频繁出现在各个行业大会，被各大厂、传统行业数字化部门、追求高效能的团队不断的提及并迭代，比如阿里的效能改进211愿景，腾讯的智研平台，百度工程能力白皮书。那么为什么软件研发效能会成为热词，有哪些合适的软件研发效能指标呢? 本文想尝试回答这两个问题。(下篇将尝试构建一个根据团队上下文的软件研发效能推荐指标图表，和一些实际度量指标的案例。)
为什么软件研发效能会成为热词？
咱们先看看现有的问题， 与传统制造业相比，软件研发行业还很年轻，并没有达到传统行业的大规模流水线的生产方式，这解释了为什么没有一种统一的，被广泛认可的方法来衡量开发人员或研发小组的效能。研发效能的度量很大程度上取决于公司的类型，规模，文化，与之合作的项目类型以及其它诸多因素。 甚至某些小而精，依靠聪明才智和资深经验的创业团队，不用度量研发效能，团队依然非常高效。
很显然，10年前使用代码行数(Lines of code)来度量研发效能的方式已经不适用现代敏捷过程对软件研发的理解了。以前关注代码产出，而不是业务成果，以前关注个人绩效，而不是团队效能。例如: 随着公司和开发人员向着价值驱动和基于团队开发方向的拉通，代码行数不再具有任何意义。100行代码是否比20行好？行数是否告诉你取得了良好的进展，还是只是一个没有上下文的抽象指标？软件企业都在寻求其它有效的指标来度量研发效能。
同时，如今的软件行业已经不再是“以大吃小”的时代了，而是转变成了“以快吃慢”的时代。对于很多大型软件企业、传统行业的数字化部门。原本“大”是优势，现在却陷入了“大船难掉头”的尴尬。如何破局？研发效能具体来讲就是从需求转化成软件或者服务的能力。改善研发效能从某种方面也在试图解决“大船难掉头”的尴尬。
研发效能试图在解决度量和让研发变快的问题，那为什么会成为热词? 为什么最近几年各大厂、传统行业数字化部门、追求高效能的团队，都纷纷开始在研发效能领域发力，我认为这背后的原因有以下三点：
从土壤和环境的角度来看，类似高速移动网络的普及为智能手机和App培育了土壤和环境。4G移动网络的普及，让人们可以方便、快速的接入互联网，为智能手机和App铺好了路。现代软件研发的各个环节已经全面数字化，为研发效能的数据收集和度量做好了准备。比如: 电子看板管理任务状态，可数字化团队协作情况。Git等工具管理代码提交，可数字化开发过程。持续部署流水线管理发布过程，可数字化发布情况。DevOps云上部署、编排、监控，可数字化产品运维状态。
从组织协作角度来看，很多公司都有“谷仓” (The Silo Effect) 局部优化但是无法全局优化的困境。从需求确定到开发完成优化了，但是当用户需求被设计好以后需要很长时间才能传递给开发。当产品上线后，线上问题需要很久才能从运维传递给开发人员并修复，从而影响全局效率。基于协作流程的优化，打破流程中的“谷仓”，去除不必要的等待，让价值流动快起来，也是研发效能试图解决的问题。
从资源的角度来看，以前业务的快速发展用烧钱的方式，人海战术换取更快的市场占有率达到赢家通吃是最佳选择，那时候关心的是软件产品输出，研发效率可以用人、用钱填上。 但是随着时间的推移，还有这么多从业人员可填吗？即便有了这么多人还能砸这么多钱吗？每年软件研发人员的毕业生有限，然而行业对人才的需求从没削减过，当抽干一线城市的人才，各个大厂已经开始下沉到二、三线城市的大学招人了。同时，随着产品利润的下降，需要更多的获客，回馈客户，需要开始节流了，节流就是研发效能的提升，同样的资源，同样的时间来获得更多的成果。
有哪些合适的软件研发效能指标呢? 上面基本回答了研发效能为什么会成为热词，有哪些合适的软件研发效能指标呢? 要度量哪些数据呢？根据不同的场景和目标人群需要给出相应的度量指标。正如《关键对话》中建议的，需要根据信息接收者的兴趣点来构建沟通策略和沟通内容。从研发效能DevOps角度 《Accelerate》 这本书给出了4个指标和评价标准。研发效能是一个比较大的话题，如何根据不同的关注点，给出不同的指标呢？ Roy Osherove 的 “Lies, Damned Lies, and Metrics”也给出了很好的归类。根据我们在项目中的实际使用和经验总结，这里把当前常用的度量指标归类如下：
规划与进度：评估进度，获取背景信息和上下文，知道任务何时完成，预测问题（未来），对问题复盘与回顾（过去）。
燃尽图 (每个迭代/每个发布) （Burndown chart sprint/release)
速率图 (Velocity chart)
标准方差 (Standard deviation)
吞吐量（Throughput)
累积流程图 (Cumulative flow diagram)</description></item><item><title>QA行业认证杂谈</title><link>https://qe-community.github.io/posts/qa_certificates/</link><pubDate>Mon, 19 Apr 2021 13:56:59 +0800</pubDate><guid>https://qe-community.github.io/posts/qa_certificates/</guid><description>本文由寇永发表 今天周末的杭州还是阴雨连绵，像极了多年前在安徽经历过的梅雨季节：三月就下了一场雨，一场雨下了三个月。既然已经数次领略临安烟雨，也哼罢了“西湖美景举世无双”的太平歌词，今天索性坐在案前搬文弄墨来。虽无红袖添香，但有茗茶相伴，同样快意。
入QA行业多年，回想起来一直摸石头过河，深一脚浅一脚，沉浮由它，竟忽视了时不时看看周围，没准儿能碰上一股浪劲儿，随着树叶一起早些过河呢。最近正巧在对QA行业的能力认证做一番搜罗学习，正好拿出来聊聊，大家探讨。
现在QA行内领先的职业认证，有这四大主角：
ISTQB - International Software Testing Qualification Board QAI cert - Quality Assurance Institute certificates 软件评测师 - 隶属于软考 CBSTC - 软件测试能力认证联盟 至于为什么要选四个，或者说是凑四个（结尾你会有感觉）。倒是没什么逻辑，纯粹个人爱好，毕竟四开头的东西都蛮出名，比如四大发明，四大名著，四大天王，还有真的“四大”。
五维对比 大家还记得那档（或许是曾经）火爆异常的综艺《非X勿扰》，会把嘉宾从不同维度来展示，如情感经历，生活爱好，家庭情况等，以便观众们能更全面了解，选取天选之爱。
既然我们是横览业内知名的四大认证，也免不了摊平了比一比，而不能一股脑堆上来让观众摘择。略加思索，就有了下面非X勿扰-比武招亲的打趣儿文字，待看四大认证谁称英雄。
知名度 在这个维度，依认证机构官方的推介力度，ISTQB和软考(软件评测师)知名度无疑更强，现存持证人数也不分上下。其认可范围，一中一外，一楚一汉，隔河相对，倒也相安。QAI历史悠久，但影响力只在美印两地。至于帅气小生CBSTC，初来乍到，随出身名门，但认证行业实力说话靠不了爹娘，起点尤高也需期后续。
认证结构 认证结构组成来谈，ISTQB倒是包罗万象，涵盖自动化技术，专项测试，测试管理，流程演进种种，可谓达到了大一统。QAI看则更专注于质量和业务本身的两三点，或许是对ISTQB明知不敌，而聚力亮剑，勇者可敬。然而软考只软件评测师一例应敌，略显单薄，或许背靠官家，参与一二，胜负遂缘，佛系大气。
培训资源 从培训的师资力量和多元方式看，ISTQB除了那有时难倒英雄汉的价格之外，和软件评测师之间又一次不分伯仲。QAI基本可算经过之前几年一番硬拼但力弱不敌，已被国内培训界置为弃子。至于CBSTC在此处，和上个维度一样，我只觉得巧妇难为，想捧但无从谈起。
考试3W (Where, When, What) 考试相关就提两点，其一为花费，这ISTQB不允许跳级报考，远看像是个聚宝盆，近观感觉在打劫。其二为考试题型，评测师和QAI的简答主观题倒是正对了试图以认证检验能力的人心。而CBSTC (此处省略10个字)。
含金量 对于含金量，的确很难分个高低上下。为什么呢？ 这就跟对比哪个品牌的鼻毛剪更好用一个道理，你趁着鼻毛不留神猛然拔掉，不快，不香吗？
当然话还需分两说，在特定的场合这些认证还是很有用处的，比如评职称，投标资格等，只要做到对症就行。有时还会有意外收获，就像报考心理咨询师认证之前，谁也不会预料到持证以后与男性朋友之间会产生心理隔阂，却不期而遇成了千百女神之友。 如何选择 还是那档（祝愿它一直）火爆的综艺，该看的能看的都看过了，虽然各有特点难分上下但心中也有了初略的想法。那谁才是那个注定的它呢？这还得与自身条件做个参照，对比前世今生，看看哪一款更合适。
就像这样： 如果你对QA行业前景已经看空，敬请绕行，可以另觅良缘。 或者 如果你是毕业生或者入行QA行业两三年，ISTQB是合适的选择 如果你计划走偏技术QA的路线，ISTQB是合适的选择 如果你计划走偏业务或管理方面的路线，QAI是合适的选择 如果你希望检验自己的自学能力，QAI是合适的选择 如果你想系统性的温习计算机行业的理论，软件评测师是合适的选择 如果你怀念大学时候的学习热情想重拾那颗坚定的心，软件评测师是合适的选择 如果你已过而立，软件评测师是合适的选择，国家中级职称可以在年老时可以多领一些退休金 如果你追求代码整洁和技术卓越，请原谅我此处逻辑的冗余 但是 人生从来不是“如果&amp;hellip;就&amp;hellip;”这样的逻辑推理剧，而更多是“当&amp;hellip;会&amp;hellip;”的感性情景剧。 这个时候，还有终极一招，那就是从小到大屡试不爽的“遇事不决，抓阄解决”了。
隐约中，我仿佛看见满天都是写着A, B, C, D的小纸团在飞舞。不过，我希望可以暖心提醒你“拿掉那个写着D的纸团吧”，不然你会有一种买了套还没挖地基的商品期房的感觉 -&amp;gt; 交房的日子遥遥无期。
茶，业已三泡，清香渐隐。时至正午，该填填肚子了，到此作罢。 人是铁饭是钢嘛，周末快乐</description></item><item><title>如何发表文章？</title><link>https://qe-community.github.io/posts/second-author/</link><pubDate>Sat, 17 Apr 2021 00:43:59 +0800</pubDate><guid>https://qe-community.github.io/posts/second-author/</guid><description>本文由author2发表 Hi，如果你想把自己的文字发表到我们的博客平台，很简单。
条件： 博客内容为原创 博客文字对客户项目相关敏感信息经过脱敏处理 如何联系？ 关注微信公众号：QE自由行，并留言即可</description></item><item><title>测试代码高亮</title><link>https://qe-community.github.io/posts/code-highlight/</link><pubDate>Fri, 16 Apr 2021 00:43:59 +0800</pubDate><guid>https://qe-community.github.io/posts/code-highlight/</guid><description>测试代码高亮 Java public class SomeClass() { public void someMethod() { String message = &amp;#34;Hello&amp;#34;; System.out.println(message); } } JavaScript const message = &amp;#34;Hello&amp;#34;; console.log(message) Shell message=&amp;#34;Hello&amp;#34;; echo ${message}</description></item></channel></rss>